{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> COMP2420/COMP6420 - Introduction to Data Management, Analysis and Security</h1>\n",
    "\n",
    "<h2 align='center'> Lab 06 - Decision Trees & Clustering</h2>\n",
    "<h5 align='center'><sub> Author: Afzal Ahmad, 2020 </sub></h5>\n",
    "\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "Dear Students, Please do not worry if you are finding it difficult to finish all the lab exercises during the allocated time. The labs were designed to help you think about the weekly topic being studied in depth and contain exercises in increasing order of complexity. You can finish what's left in your free time at home or in the computer labs on campus. If you need input, please go to the drop-in sessions available weekly and/or post your questions on Piazza.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim\n",
    "There are three main aims in this lab:\n",
    "- Introduce you to the Decision Tree algorithm\n",
    "- Describe the difference between supervised and unsupervised algorithms\n",
    "- Introduce the Clustering algorithm as an unsupervised algorithm\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "The following course learning outcomes apply to this lab:\n",
    "- L03: Demonstrate basic knowledge and understanding of descriptive and predictive data analysis methods, optimization and search, and knowledge representation.\n",
    "- L04: Formulate and extract descriptive and predictive statistics from data\n",
    "- L05: Analyse and interpret results from descriptive and predictive data analysis\n",
    "- L06: Apply their knowledge to a given problem domain and articulate potential data analysis problems\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Before starting this lab, we suggest you complete the following:\n",
    "- Watch the lectures this week\n",
    "- Complete both Lab04 (regression) and Lab05 (classification) and become familiar with both categories of techniques\n",
    "\n",
    "\n",
    "The following functions may be useful for this lab:\n",
    "\n",
    "| Function                     | Description |\n",
    "| ---:                         | :---        |\n",
    "| `DecisionTreeClassifier`, `DecisionTreeRegressor`              | create instances of the respective Decision Tree modules |\n",
    "| `tree.export_graphviz(model, output)`         | export `model`'s tree construction to the `output` file |\n",
    "| `KMeans()`, `PCA()`  | create instances of the K-Means Classifier and Principle Components Analysis modules |\n",
    "| `kmc_model.labels_` | returns `N` cluster labels, where `N` is the number of observations in the fitted data |\n",
    "| `kmc_model.cluster_centers_` | returns `K` cluster centres, where `K` is the number of clusters\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder          # encooding variables\n",
    "from sklearn.model_selection import train_test_split    # testing our models\n",
    "from sklearn.model_selection import cross_validate # cross validation\n",
    "\n",
    "# decision trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "\n",
    "# k-means clustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt    # plotting, if you need it\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "np.random.seed(5123690)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Planting Roots\n",
    "\n",
    "We've still got one more **supervised** (more on this later, if you're not already familiar) machine learning algorithm to introduce: **Decision Trees**. This is because it's a versatile algorithm; it can be used for **both numerical regression and categorical classification**. Before we dive into it, let's go through some terminology:\n",
    "- a Decision Tree consists of **nodes** and **branches**, and (like most trees you'll see in computer science) looks like an upside-down tree, with the starting point at the top and the branches growing downwards\n",
    "- the \"starting point\" is called the **root node**, and this represents the whole set of observations in the data\n",
    "- intermediate nodes, called a **decision node**, is a node that represents a subset of the observations\n",
    "- each \"ending point\" is called a **leaf node**, or terminal node, and is defined as a node that has no branches leading (downwards) from it\n",
    "- each non-leaf node will have (usually two) **branches**, with each branch representing a decision - for example, the left branch might split the data dependent on `Age<=10` and thus the right branch will have the remaining data, with `Age>10`\n",
    "\n",
    "The Decision Tree algorithm will try to choose these branches so that the training data in the leaf nodes are homogenous. As an example, suppose you have a two-class classification, `Survival` = 0 or 1. The algorithm will try to construct the tree so that each leaf node has either all 0s or all 1s as the targets.\n",
    "\n",
    "How does it do this? Using metrics called **Entropy** and **Information Gain**. Loosely, the entropy of a set of information is based on how similar all points are; when all information points have the same value(s), entropy is 0, and when all information points have unique value(s) entropy is maximised. In the context of Decision Trees, the algorithm tries to minimise the entropy of the information in each leaf node. Thus, at each decision node, it maximises the Information Gain, which is the difference between the entropy before the split and the entropy after splitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Classifying Trees\n",
    "\n",
    "Time to use Decision Trees for a classification problem. Because we've been using the Titanic dataset in Lab05, let's use it again. Here's the description of the columns, in case you need to refer to them:\n",
    "\n",
    "| Name           | Description |\n",
    "| ---:           | :---        |\n",
    "| `PassengerId`  | an arbitrary ID assigned to each passenger |\n",
    "| `Survived`     | status of passenger's survival<br>(`0`=No, `1`=Yes) |\n",
    "| `Pclass`       | passenger's ticket class<br>(`1`=Upper, `2`=Middle, `3`=Lower) |\n",
    "| `Name`         | full title and name of passenger |\n",
    "| `Sex`          | gender of passenger |\n",
    "| `Age`          | age of passenger<br>fractional if less than 1, xx.5 if estimated |\n",
    "| `SibSp`        | number of siblings and spouses aboard<br>brother / sister / stepbrother / stepsister / husband / wife |\n",
    "| `Parch`        | number of parents and children aboard<br>mother / father / daughter / son / stepdaughter / stepson |\n",
    "| `Ticket`       | ticket ID |\n",
    "| `Fare`         | passenger fare ($) |\n",
    "| `Cabin`        | cabin number |\n",
    "| `Embarked`     | port of embarkation<br>(`C`=Cherbourg, `Q`=Queenstown, `S`=Southampton) |\n",
    "\n",
    "#### 2.1 I Tried So Hard, And Got So Far\n",
    "\n",
    "The `DecisionTreeClassifier` module is very similar to other Scikit-Learn modules you've been using. Import the data, transform your data to prepare it for classification, create a Decision Tree module instance, split the data, fit the model using the training data, and score the model on both the training and testing sets. In short: **import**, **prepare**, **split**, **fit**, **score**. Maybe you can make a rhyme out of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import, prepare, split, fit, score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice anything interesting? Unless you changed the parameters of the `DecisionTreeClassifier`, you'll likely find that your training score and your testing scores differ significantly. Why might that be?\n",
    "\n",
    "#### 2.2 But In The End, It Didn't Even Matter\n",
    "\n",
    "Luckily, you can view the actual tree that the algorithm created. To do this, run `tree.export_graphviz(<model>, \"tree.dot\")`, where `<model>` is the name of the Decision Tree model you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: export tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there's the question of compiling the exported `.dot` file into an image that you can read. This is optional, but highly recommended to understand how Decision Trees work. There's a few ways you can do this:\n",
    "- Set up the tools on your machine to be able to convert it in the terminal (note that **this is unlikely to work on the CECS lab computers**):\n",
    "    - Ubuntu\n",
    "        1. `sudo apt install graphviz`\n",
    "        2. `dot -Tpng tree.dot -o tree.png` (in the correct directory)\n",
    "    - OSX (using Homebrew)\n",
    "        1. `brew install graphviz`\n",
    "        2. `dot -Tpng tree.dot -o tree.png` (in the correct directory)\n",
    "    - Windows\n",
    "        1. Install the appropriate packages from [GraphViz on Gitlab](https://graphviz.gitlab.io/_pages/Download/Download_windows.html)\n",
    "        2. Ensure GraphViz is within your PATH\n",
    "        3. In PowerShell: `dot -Tpng tree.dot -o tree.png` (in the correct directory)\n",
    "- Use an online converter which takes the `.dot` file and outputs a `.png` file. One such example is [this website](https://onlineconvertfree.com/convert-format/dot-to-png/). However, **be aware that you are responsible for any risks** that you take in using this or other services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you were able to obtain the image of the tree construction successfully, analyse it. In particular, look at the leaf nodes and the `samples` and `values` for each leaf. What do you notice, and why might this affect the testing score?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TODO: analyse the tree (highly recommended)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you weren't able to look at the tree, the short story is that the leaf nodes contained (mostly) only values that belonged to one target value (i.e. data relating to each node was usually either all `Survived`=1 or `Survived`=0. Of course, we shouldn't expect anything else - the Decision Tree algorithm is to do exactly that. As a result, the tree was also incredibly large, and up to 20 layers deep. \n",
    "\n",
    "What does this lead to? The kryptonite of machine learning: **overfitting**. Let's look at how to combat this.\n",
    "\n",
    "Use `help(DecisionTreeClassifier)` to look at the parameters available when fitting a model. In particular, look at `max_depth`, `min_samples_split` and `min_samples_leaf`, and see how these might affect the construction of the model's tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: investigate the algorithm parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Let's See How Far We've Come\n",
    "\n",
    "Re-fit the model and find the training and testing scores, but this time set the parameters for `max_depth`, `min_samples_split` and/or `min_samples_leaf` to avoid overfitting. If you get stuck, export the model and view the tree to see how you can improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: re-fit the model with parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll likely still find that the training score is higher than the testing score, but it should be much more indicative than it was before. Careful not to be too specific with these parameters, as this can lead to treating the testing set like a second training set to maximise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2.4 Find the best parameter: cross validation and grid search\n",
    "\n",
    "Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called overfitting. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a test set ```test_X```, ```test_y```. Note that the word “experiment” is not intended to denote academic use only, because even in commercial settings machine learning usually starts out experimentally. Here is a flowchart of typical cross validation workflow in model training. The best parameters can be determined by **grid search** techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./grid_search_workflow.png\" alt=\"grid_search_flow\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluating different settings (“hyperparameters”) for estimators, such as the ```C``` setting that must be manually set for a decision tree, there is still a risk of overfitting on the test set because the parameters can be tweaked until the estimator performs optimally. This way, knowledge about the test set can “leak” into the model and evaluation metrics no longer report on generalization performance. To solve this problem, yet another part of the dataset can be held out as a so-called “validation set”: training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.\n",
    "\n",
    "However, by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets.\n",
    "\n",
    "A solution to this problem is a procedure called **cross-validation** (CV for short). A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called k-fold CV, the training set is split into k smaller sets (other approaches are described below, but generally follow the same principles). The following procedure is followed for each of the k “folds”:\n",
    "\n",
    "A model is trained using  of the folds as training data;\n",
    "\n",
    "the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
    "\n",
    "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. This approach can be computationally expensive, but does not waste too much data (as is the case when fixing an arbitrary validation set), which is a major advantage in problems such as inverse inference where the number of samples is very small. (https://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./grid_search_cross_validation.png\" alt=\"grid_search_flow\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Now, let's see how to use cross validation to evaluate the models we build for 2.1 and 2.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "scores = cross_validate(dt, titanic_X, titanic_y, cv=5 ,scoring='accuracy')\n",
    "print(f\"the 5 fold average cross validation score of model in 2.1 is {np.mean(scores['test_score']):.4f}\")\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=10, min_samples_split=10, min_samples_leaf=10)\n",
    "scores = cross_validate(dt, titanic_X, titanic_y, cv=5 ,scoring='accuracy')\n",
    "print(f\"the 5 fold average cross validation score of model in 2.3 is {np.mean(scores['test_score']):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Now, let's first determine the hyperparameters range you want to search.\n",
    "For this is the first time we do a grid search over parameters, we have done it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_dict = {'max_depth': range(2,20,2),\n",
    "                   'min_samples_split': range(2, 20, 2), \n",
    "                   'min_samples_leaf': range(2, 20, 2) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Todo: How many train-test iterations will be needed if you want to do a 5-fold cross validation for each of the parameter combinations in ```hyperparameters_dict```?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.3 Do a grid search for all the combination in the ```hyperparameters_dict```\n",
    "    1. report the best parameter combination you find.\n",
    "    2. report the best average accuracy you find for the best parameter combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in the blank\n",
    "best_score = -1\n",
    "best_parameter = {'max_depth': 0,\n",
    "                   'min_samples_split': 0, \n",
    "                   'min_samples_leaf': 0 }\n",
    "\n",
    "for max_depth in hyperparameters_dict['max_depth']:\n",
    "    for min_samples_split in hyperparameters_dict['min_samples_split']:\n",
    "        for min_samples_leaf in hyperparameters_dict['min_samples_leaf']:\n",
    "            dt = DecisionTreeClassifier(...)\n",
    "            \n",
    "            scores = cross_validate(...)['test_score']\n",
    "            mean_score = np.mean(scores)\n",
    "            if mean_score > best_score:\n",
    "                best_parameter['max_depth'] = ...\n",
    "                best_parameter['min_samples_split'] = ...\n",
    "                best_parameter['min_samples_leaf'] = ...\n",
    "                best_score = ...\n",
    "                \n",
    "print(f'the best model parameter: {best_parameter} and the best mean accuracy: {best_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.5 Now use the best set of parameter and train on the ```train_x``` set and test it again on the ```test_x``` data set we created in 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: train the model with best set of the parameters and evaluate the train and test score\n",
    "dt_best = DecisionTreeClassifier(...)\n",
    "dt_best_model = dt_best.fit(train_x, train_y)\n",
    "print(\"Best Model Training Score:\", dt_best_model.score(...))\n",
    "print(\"Best Model Testing Score: \", dt_best_model.score(...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import, prepare, split, fit, score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this testing score to the score you got in Lab04 - which is higher? Of course, keep in mind that no single machine learning algorithm is better than the rest; each has their advantages and disadvantages depending on the data that they're given."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TODO: discussion on Decision Trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't already done so, export the tree and view it if possible. How does it differ from the classifying tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: export and view, if possible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: No More Adult Supervision\n",
    "\n",
    "#### 3.1 Supervised vs Unsupervised\n",
    "\n",
    "So far, all of the machine learning algorithms (linear regression, logistic regression, kNN and Decision Trees) have been **supervised** algorithms. If you're not already familiar, a supervised algorithm **requires that the target is labelled**. For example, we've been using the Titanic dataset which has `Survived` as either `0` or `1` for each person. The name \"supervised\" comes from the idea that you, the supervisor, have given it everything it needs to work with.\n",
    "\n",
    "This is in contrast to **semi-supervised** (not covered in this course) and **unsupervised** algorithms. Unsupervised algorithms have **no labelled target values**, and it's the job of the algorithm to categorise the data so that you can determine what label each category is. One example that we'll see soon is a scenario where a store wants to categorise customers so that they can understand the distinct types of shoppers that visit their store, and potentially advertise relevant products towards them.\n",
    "\n",
    "The unsupervised algorithm we'll be teaching in this course is **K-Means Clustering**. This splits the data into a specified number of clusters to be analysed by you later. **Don't get mixed up between k-Nearest Neighbour and K-Means Clustering**, especially because both are graphical, distance-based algorithms that use a `K` parameter as one of its main aspects.\n",
    "\n",
    "#### 3.2 Iris Clusters\n",
    "\n",
    "Let's start off easy. Import the Iris dataset (`data/IRIS.csv`) and **perform a clustering based on all the columns except the `species` column**. When creating the module instance, set `n_clusters=3` (why?). **Save the model with the name `kmc_model`**. Don't worry about splitting or testing your data - after all, unsupervised algorithms have no target labels to test with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import and fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've fit the model with the correct name, you should be able to use the next code block to plot your clusters. Change `dim_1` and `dim_2` to look at the data using different features (essentially, looking at it from a different angle). After you've explored that, change the `n_clusters` parameter above to a different number to see how that changes the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to change the colours to your liking\n",
    "colors=[\"red\",\"blue\",\"green\",\"purple\",\"orange\"]\n",
    "dim_1 = 0    # change, between 0 and 3\n",
    "dim_2 = 1    # between 0 and 3, dim_2!=dim_1\n",
    "\n",
    "# plotting with different coloured clusters and showing cluster centres\n",
    "plt.figure(figsize=(12,8))\n",
    "for i in range(np.max(kmc_model.labels_)+1):\n",
    "    plt.scatter(iris[kmc_model.labels_==i].iloc[:,dim_1], iris[kmc_model.labels_==i].iloc[:,dim_2], label=i, c=colors[i], alpha=0.5)\n",
    "plt.scatter(kmc_model.cluster_centers_[:,dim_1], kmc_model.cluster_centers_[:,dim_2], label='Cluster Centers', c=\"black\", s=200)\n",
    "plt.title(\"K-Means Clustering of Iris Data\",size=20)\n",
    "plt.xlabel(iris.columns[dim_1], size=16)\n",
    "plt.ylabel(iris.columns[dim_2], size=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the data and compare the `species` label to the `kmc_model.labels_` label. Do the labels accurately categorise the species?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: explore data vs clusters\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frustrated that you can only see in two dimensions on a screen at a time? What if you had 10 variables to look at? That'd give you 45 different angles to look at the clusters from!\n",
    "\n",
    "Fortunately, we can reduce the dimensionality of the data using **Principle Components Analysis** (PCA), allowing you to look at the data from the \"best\" angle. PCA decomposes all of the variables into the desired number of dimensions that maximise the variance between them. As a result, you can look at the data on a screen that can only show two dimensions, but it also means that the dimensions that you view the data at doesn't have much meaning in the context of the data.\n",
    "\n",
    "Use the `PCA` module in Scikit-Learn to **reduce the data down to two dimensions**, using the `fit_transform` function with `n_components=2`. Be sure to exclude the `species` column beforehand. Save the decomposition to an object called `iris_reduced`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: decompose the iris data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now redo the clustering above using the `iris_reduced` data, and run the code block below to plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: re-cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to change the colours to your liking\n",
    "colors=[\"red\",\"blue\",\"green\",\"purple\",\"orange\"]\n",
    "\n",
    "# plotting with different coloured clusters and showing cluster centres\n",
    "plt.figure(figsize=(12,8))\n",
    "for i in range(np.max(kmc_model.labels_)+1):\n",
    "    plt.scatter(iris_reduced[kmc_model.labels_==i][:,0], iris_reduced[kmc_model.labels_==i][:,1], label=i, c=colors[i], alpha=0.5)\n",
    "plt.scatter(kmc_model.cluster_centers_[:,0], kmc_model.cluster_centers_[:,1], label='Cluster Centers', c=\"black\", s=200)\n",
    "plt.title(\"K-Means Clustering of Iris Data\",size=20)\n",
    "plt.xlabel(\"Principle Component 1\", size=16)\n",
    "plt.ylabel(\"Principle Component 2\", size=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can see the data from the best angle, without needing to look at it with different dimensions to make sure the clustering is well-separated. You might not see much difference here, but it'll certainly help as you move on to more complicated datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Crowds of Customers\n",
    "\n",
    "Let's do the same as above, but this time we'll be working on customer data.\n",
    "\n",
    "Import the data (`data/customers.csv`) and perform a clustering on the reduced data (i.e. after using PCA). We leave it up to you to **decide how many clusters you should create**, as realistically this is usually not given to you. Ideally, you should **maximise the distance between clusters**, and **minimise the distance within clusters**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create clustering for customers data\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From the principle components, we see that there are 5 distinct groups, so we choose 5 clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you've created the clusters, be sure to plot the results to see if it can be improved. Once you've done that, **create a DataFrame for each cluster's data** and identify their main attributes - how do these clusters differ from each other? *Hint: your analysis can include studying the mean age, average annual income & deviation in income, size of each cluster, and male-to-female ratio of each cluster.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: split data and analyse\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework & Extension Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Regressing Trees\n",
    "\n",
    "Now let's see how the Decision Tree algorithm works for a regression problem. We'll use the same Houses dataset that was used in Lab04; the description of the variables are listed below:\n",
    "\n",
    "| Name           | Description |\n",
    "| ---:           | :---        |\n",
    "| `LotArea`      | size of lot in square feet |\n",
    "| `OverallQual`  | rating of the overall material and finish of the house (higher is better) |\n",
    "| `OverallCond`  | rating of the current condition of the house (higher is better) |\n",
    "| `YearBuilt`    | original construction date |\n",
    "| `YearRemodAdd` | date that the last remodelling was done (=`YearBuilt` if no remodelling)\n",
    "| `GrLivArea`    | above-ground living area in square feet |\n",
    "| `FullBath`     | number of above-ground, full-sized bathrooms |\n",
    "| `BedroomAbvGr` | number of above-ground bedrooms |\n",
    "| `KitchenAbvGr` | number of above-ground kitchens |\n",
    "| `GarageArea`   | size of garage in square feet |\n",
    "| `YrSold`       | year that the lot was sold |\n",
    "| `LotShape`     | general shape of property<br>(`Reg`=Regular, `IR1`=Slightly irregular, `IR2`=Moderately irregular, `IR3`=Very irregular)\n",
    "| `LotConfig`    | configuration of lot<br>(`Inside`, `Corner`, `CulDSac`=Cul-de-sac lot, `FR2`=Frontage on 2 sides, `FR3`=Frontage on 3 sides)\n",
    "| `SalePrice`    | property's sale price in dollars |\n",
    "\n",
    "Use the `DecisionTreeRegressor` module to fit a regression Decision Tree model to this data to predict `SalePrice`, and report both the training and testing scores. Remember to set the parameters for the module instance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
