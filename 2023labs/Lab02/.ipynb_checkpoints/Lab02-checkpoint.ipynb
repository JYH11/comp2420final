{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> COMP2420/COMP6420 - Introduction to Data Management, Analysis and Security</h1>\n",
    "\n",
    "<h2 align='center'> Lab 02 - NumPy, Pandas, and other Python Packages</h2>\n",
    "\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim\n",
    "Our aim in this lab is:\n",
    "- Become familar with the use of the Python packages NumPy & Pandas.\n",
    "- Learn some basic functionality of the aforementioned packages for future use\n",
    "\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "There are no distinct linkages to the learning outcomes of the course, as this lab forms the baseline for using additional Python packages and other tools to acheive the learning outcomes described on [Programs & Courses](https://programsandcourses.anu.edu.au/course/COMP2420#learning-outcomes) in the coming weeks.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Before starting this lab, we suggest you complete the following:\n",
    "- Watch the **Data Science Tools** lecture, it really will help!\n",
    "\n",
    "<br>\n",
    "\n",
    "The following documents will be useful for this lab:\n",
    "\n",
    "- [NumPy Cheatsheet](./helpManuals/Numpy_CheatSheet.pdf)\n",
    "- [Pandas Cheatsheet pt1](./helpManuals/Pandas_CheatSheet_1.pdf)\n",
    "- [Pandas Cheatsheet pt2](./helpManuals/Pandas_CheatSheet_2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detour: Introduction to Numpy & Pandas\n",
    "\n",
    "In Lab01, we covered the basics on Python (among other items), however Python by itself is limited in it's functionality. Luckily, Python's development community is rich and a number of optional packages exist to provide the functionality we require. Two of the most widely used packages (and the two we will be covering), are **NumPy** and **Pandas**. In a 2018 survey of data scientists by [Figure-Eight](https://www.figure-eight.com), the most popular machine learning frameworks identified by respondents were Pandas and NumPy. Naturally, it seems like a good place to start on your journey into data science.\n",
    "\n",
    "**NumPy**, initially released in 2006 for Python 2.x, and 2011 for Python 3.x, provides fast mathematical computation of arrays and matrices. Optimised using underlying functionality written in the _C_ programming language, NumPy provides much faster implementations of array functionality. Since, arrays and matrices are an essential part of the Machine Learning ecosystem, NumPy is commonly associated with other packages in the machine learning ecosystem  such as SciPy, Pandas and Matplotlib (to name a few).\n",
    "\n",
    "**Pandas** is another widely used package for data analysis in the Python language. Originally written for performing quantitative analysis on finanical data by a US-based investment firm, Pandas provides easy to use and highly stable data manipulation & analysis tools. Once again optimised by the C programming language, Pandas provides a much faster implementation for 2 dimensional array-style objects, notwithstanding the simplicity of function calls for analysis.\n",
    "\n",
    "We define packages such as **NumPy** and **Pandas** as additional (optional) packages for Python as they are not included in the standard Python installation. This is one of the reasons why we use the _Anaconda_ distribution as our Python package manager, as it installs these items by default. Without this, there would be additional installs necessary through the _pip_ package manager (not covered) to ensure we had all the right tools. Long story short, be glad we are using Anaconda where everything is ready to go!\n",
    "\n",
    "Before getting into the lab, lets show a quick little experiment on the C vs Python implementation debate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detour: Nothing on NumPy\n",
    "\n",
    "The following is two examples of adding two lists, each with 10 million items. We find the mean of 5 runs, as this provides a better indication of the speed taken to perform this action. Otherwise, other processes on your computer might skew the results slightly. \n",
    "\n",
    "Notice the speed of the NumPy implementation is much faster than the traditional Python implemention. Maybe those \"C purists\" are onto something..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Imports \n",
    "# Notice how we follow the same setup as shown in Lab01\n",
    "# Without this, the Python environment does not know these items exist\n",
    "# These packages are usually optional for Python, \n",
    "#     but are installed in the Anaconda distribution\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# Including extra packages for the sake of the experiment.\n",
    "# These packages are inbuilt to the standard Python distribution\n",
    "from timeit import default_timer as timer\n",
    "import statistics as st\n",
    "\n",
    "# Ignoring warnings for now.\n",
    "# This is because there is some depreciated functionality NumPy uses that is outside of\n",
    "#     our control\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pure Python method takes 2.677 seconds\n",
      "The NumPy method takes 0.065 seconds\n"
     ]
    }
   ],
   "source": [
    "# A function to determine the speed taking to generate & add \n",
    "#     two lists of 10 million items.\n",
    "# The action of addition is performed a number of times to gain an average.\n",
    "def trad_listaddition():\n",
    "    times = []\n",
    "    for x in range(5):\n",
    "        start = timer()\n",
    "        # range() provides an iterator object, so we must unpack this into a list \n",
    "        #     for the fast X+Y function\n",
    "        X = [*range(10000000)] \n",
    "        Y = [*range(10000000)]\n",
    "        Z = [X[i] + Y[i] for i in range(10000000)]\n",
    "        end = timer()\n",
    "        times.append(end - start)\n",
    "    return round(st.mean(times), 3)\n",
    "\n",
    "def numpy_listaddition():\n",
    "    times = np.zeros([5]) # Notice we have to define the list size at the start\n",
    "    for x in range(5):\n",
    "        start = timer()\n",
    "        # np.arange() returns an ndarray, so no extra unpacking necessary\n",
    "        X = np.arange(10000000) \n",
    "        Y = np.arange(10000000)\n",
    "        Z = np.add(X,Y)\n",
    "        end = timer()\n",
    "        times[x] = end - start\n",
    "    return np.round(np.mean(times), decimals=3)\n",
    "\n",
    "# Notice we can specify a variable in our print function in a number of ways\n",
    "print(\"The pure Python method takes %s seconds\" % trad_listaddition())\n",
    "print(\"The NumPy method takes\", numpy_listaddition(), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't even need to hardcode the experiment to ensure that NumPy will be faster on your computer, because it will be. Feel free to run the above code multiple times to prove the point!\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: **Its About Time!**\n",
    "\n",
    "Taking inspiration from the little speedtest we have above, the following exercise is designed to showcase how the C optimised code of NumPy will show vanilla Python who is boss, while teaching you some new functions in the process.\n",
    "\n",
    "### Detour: Why do we care about time?\n",
    "\n",
    "It may seem pedantic to consider the time it takes for smaller functions, but everything adds up. While theoretical computational complexity (such as \"Big O\" notation, covered in COMP1110, COMP3600 and other courses) is important, there is further considerations to be made when implementing programs to ensure the most effecient code is being written. Sometimes that means choosing between various programming languages to avoid compilers/intepreters and abstractions between human-readable code and machine code, or in our case that means choosing the best packages within a single language.\n",
    "\n",
    "**Consider the example of entity resolution in datasets of over 10 million records.** For those not familar with entity resolution, [Data Community DC](http://www.datacommunitydc.org/blog/2013/08/entity-resolution-for-big-data) provides a short description:\n",
    "> Entity Resolution is the task of disambiguating manifestations of real world entities in various records or mentions by linking and grouping. For example, there could be different ways of addressing the same person in text, different addresses for businesses, or photos of a particular object. This clearly has many applications, particularly in government and public health data, web search, comparison shopping, law enforcement, and more.\n",
    "\n",
    "Implementing an entity resolution algorithm would require multiple passes over each applicable dataset multiple times. During this, a comparison would be required to check against every other entry in the dataset to check for duplicates, and then check for some similarity based on spelling errors, missing data, etc. While this comparison is necessary, it would be wise to find intuitive and smarter ways than a brute-force approach of traversing each list multiple times. Otherwise your algorithm might not finish this year! Another fight against time is the fact that new data would be constantly added to the list, meaning without a fast way of performing the calculation you would forever be behind, and end users requiring up to date information would suffer.\n",
    "\n",
    "So in short, it is always about time.\n",
    "\n",
    "For those interested (and as an extension), a number of ANU researchers have worked in this field and this paper is worth a read: [Scalable Entity Resolution Using Probabilistic Signatures on Parallel Databases](https://arxiv.org/pdf/1712.09691.pdf)\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1: Arranging a Flip\n",
    "First things first. Filling in the functions (where pyflip is pure python, and npflip is pure numpy), perform the following actions (they can be performed in the same step):\n",
    "- Produce a list of 50 million elements.\n",
    "- Sort the list.\n",
    "- Reverse the list.\n",
    "\n",
    "We will provide the timing code in the functions for this question, but afterwards it is up to you to include this. If you have run the timing tests above, you should already have the relevent packages imported. Otherwise, you will need to go back and run these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pure Python method takes 2.682 seconds\n",
      "The NumPy method takes 0.956 seconds\n"
     ]
    }
   ],
   "source": [
    "def pyflip():\n",
    "    times = []\n",
    "    for x in range(10):\n",
    "        start = timer()\n",
    "        ##############################################\n",
    "        # Enter Code Here\n",
    "        X = [*range(50000000)] \n",
    "        X.sort(reverse = True)\n",
    "        end = timer()\n",
    "        times.append(end - start)\n",
    "    return round(st.mean(times), 3)\n",
    "\n",
    "def npflip():\n",
    "    times = np.zeros([10]) # Notice we have to define the list size at the start\n",
    "    for x in range(10):\n",
    "        start = timer()\n",
    "        ##############################################\n",
    "        # Enter Code Here\n",
    "        X = np.arange(50000000)\n",
    "        # np.flip(X) -> reverse\n",
    "        (np.sort(X))[::-1]\n",
    "        end = timer()\n",
    "        times[x] = end - start\n",
    "    return np.round(np.mean(times), decimals=3)\n",
    "\n",
    "\n",
    "print(\"The pure Python method takes %s seconds\" % pyflip())\n",
    "print(\"The NumPy method takes %s seconds\" % npflip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Q1.2: Degrees of Heat\n",
    "Time to include a bit of math. Perform the following:\n",
    "- Based on the input of an array of 5 million elements, convert every element of the array from Celsius (°C) to Fahrenheit (°F)\n",
    "\n",
    "Hint: The equations are shown below:\n",
    "\n",
    "<img src=\"./img/fcform.png\" alt=\"Formulas\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pure Python method takes 1.156 seconds\n",
      "The NumPy method takes 0.048 seconds\n"
     ]
    }
   ],
   "source": [
    "import random as rn\n",
    "\n",
    "def pyDegree(pyInput):\n",
    "    ##############################################\n",
    "    # Enter Code Here\n",
    "    # Don't forget timing code\n",
    "    start = timer()\n",
    "    result = [((x*9/5)+32) for x in pyInput]\n",
    "    end = timer()\n",
    "    return round(end-start, 3)\n",
    "\n",
    "def npDegree(npInput):\n",
    "    ##############################################\n",
    "    # Enter Code Here\n",
    "    # Don't forget timing code!\n",
    "    start = timer()\n",
    "    result = (npInput *9/5)+32\n",
    "    end = timer()\n",
    "    return np.round(end-start, decimals=3)\n",
    "\n",
    "# Note inPy is not performed the fastest way, but is also not being counted in your timing.\n",
    "inPy = [rn.randint(-25,50) for x in range(5000000)]\n",
    "inNp = np.random.randint(-25, 50, size=5000000)\n",
    "\n",
    "\n",
    "print(\"The pure Python method takes %s seconds\" % pyDegree(inPy))\n",
    "print(\"The NumPy method takes %s seconds\" % npDegree(inNp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Q1.3: Meticulous Matching\n",
    "Taking inspiration from the entity resolution discussion above, you have two tasks:\n",
    "\n",
    "#### Q1.3.1\n",
    "- From 2 input arrays (each containing 1,000,000 elements), find the positions in the array where the array entry is the same for a given index.\n",
    "\n",
    "For example:\n",
    "```Python\n",
    "a = [1,2,3,4]\n",
    "b = [1,3,5,4]\n",
    "results = matchpositions(a,b)\n",
    "print(\"The matching positions are: \", results) \n",
    "```\n",
    "And the output would be `[0,3]`, because at positions 0 and 3 of both arrays the entries are the same.\n",
    "\n",
    "A test case has been provided to ensure your code is performing correctly, while the timing case is held seperately so you can determine which is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PyMatch(listA, listB):\n",
    "    times = []\n",
    "    for x in range(10):\n",
    "        result = []\n",
    "        start = timer()\n",
    "        ##############################################\n",
    "        # Enter Code Here\n",
    "        for x in range(len(listA)):\n",
    "            if (listA[x] == listB[x]):\n",
    "                result.append(x)\n",
    "        end = timer()\n",
    "        times.append(end - start)\n",
    "    return (round(st.mean(times), 3), result)\n",
    "# note that we return the time, and the list of matching locations as a tuple\n",
    "\n",
    "def NpMatch(nlistA, nlistB):\n",
    "    times = np.zeros([10]) # Notice we have to define the list size at the start\n",
    "    for x in range(10):\n",
    "        result = []\n",
    "        start = timer()\n",
    "        ##############################################\n",
    "        # Enter Code Here\n",
    "        result = np.where((nlistA== nlistB))[0]\n",
    "        end = timer()\n",
    "        times[x] = end - start\n",
    "    return (np.round(np.mean(times), decimals=3), result)\n",
    "# note that we return the time, and the list of matching locations as a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Passes - Python\n",
      "You found:  [0, 6]\n",
      "Test Passes - Numpy\n",
      "You found:  [0 6]\n"
     ]
    }
   ],
   "source": [
    "# Test Case\n",
    "\n",
    "# Python Test\n",
    "testAPy = [1,2,3,4,5,6,7]\n",
    "testBPy = [1,3,5,7,9,2,7]\n",
    "resultPy = PyMatch(testAPy, testBPy)\n",
    "if resultPy[1] == [0,6]:\n",
    "    print(\"Test Passes - Python\")\n",
    "    print(\"You found: \", resultPy[1])\n",
    "else:\n",
    "    print(\"Test Failed - Python\")\n",
    "    print(\"You found: \", resultPy[1])\n",
    "    \n",
    "# Numpy Test\n",
    "testANp = np.array([1,2,3,4,5,6,7])\n",
    "testBNp = np.array([1,3,5,7,9,2,7])\n",
    "resultNp = NpMatch(testANp, testBNp)\n",
    "if np.array_equal(resultNp[1], np.array([0,6])):\n",
    "    print(\"Test Passes - Numpy\")\n",
    "    print(\"You found: \", resultNp[1])\n",
    "else:\n",
    "    print(\"Test Failed - Numpy\")\n",
    "    print(\"You found: \", resultNp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pure Python method takes 0.001 seconds\n",
      "The NumPy method takes 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# Timing Case\n",
    "# This doesn't check if your code is correct, so no cheating!\n",
    "\n",
    "# Note: Python generation is not performed the fastest way, but is also not being counted in your timing.\n",
    "inAPy = [rn.randint(0,20) for x in range(10000)]\n",
    "inBPy = [rn.randint(0,20) for y in range(10000)]\n",
    "\n",
    "inANp = np.random.randint(0, 20, size=10000)\n",
    "inBNp = np.random.randint(0, 20, size=10000)\n",
    "\n",
    "print(\"The pure Python method takes %s seconds\" % (PyMatch(inAPy, inBPy))[0])\n",
    "print(\"The NumPy method takes %s seconds\" % (NpMatch(inANp, inBNp))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Q1.3.2\n",
    "- From 2 input arrays (each containing 100,000 elements), find the elements that match in the lists and return the pairs of positions that match between each array. \n",
    "\n",
    "For example:\n",
    "```Python\n",
    "a = [1,2,3,4]\n",
    "b = [1,3,5,4]\n",
    "results = matchexist(a,b)\n",
    "print(\"The matching positions are: \", results) \n",
    "```\n",
    "And the output would be `[(0,0), (2,1), (3,3)]`, where the first element in each tuple is the position in the first array, and the second element in each tuple is the position in the second array. In the above example, `(0,0)` refers to `a[0]` and `b[0]` matching, and so on.\n",
    "\n",
    "A test case has been provided to ensure your code is performing correctly, while the timing case is held seperately so you can determine which is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PyPairs(listA, listB):\n",
    "    ##############################################\n",
    "    # Enter Code Here\n",
    "    # Don't forget the timing code!\n",
    "    return\n",
    "\n",
    "## THIS IS HARD TO DO IN PURE NUMPY WELL. \n",
    "# CONSIDER COMING BACK AFTER OTHER ITEMS\n",
    "def NpPairs(nlistA, nlistB):\n",
    "    ##############################################\n",
    "    # Enter Code Here\n",
    "    # Don't forget timing code!\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case\n",
    "\n",
    "# Python Test\n",
    "pairAPy = [1,2,3,4]\n",
    "pairBPy = [1,5,7,2]\n",
    "resultpairPy = PyPairs(pairAPy, pairBPy)\n",
    "if resultpairPy[1] == [(0,0), (1,3)]:\n",
    "    print(\"Test Passes - Python\")\n",
    "    print(\"You found: \", resultpairPy[1])\n",
    "else:\n",
    "    print(\"Test Failed - Python\")\n",
    "    print(\"You found: \", resultpairPy[1])\n",
    "    \n",
    "# Numpy Test\n",
    "pairANp = np.array([1,2,3,4])\n",
    "pairBNp = np.array([1,5,8,2])\n",
    "resultpairNp = NpPairs(pairANp, pairBNp)\n",
    "if np.array_equal(resultpairNp[1], np.array([(0,0), (1,3)])):\n",
    "    print(\"Test Passes - Numpy\")\n",
    "    print(\"You found: \", resultpairNp[1])\n",
    "else:\n",
    "    print(\"Test Failed - Numpy\")\n",
    "    print(\"You found: \", resultpairNp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing Case\n",
    "# This doesn't check if your code is correct, so no cheating!\n",
    "\n",
    "inAPy = rn.sample(range(100000), 5000)\n",
    "inBPy = rn.sample(range(100000), 5000)\n",
    "\n",
    "inANp = rn.sample(range(100000), 5000)\n",
    "inBNp = rn.sample(range(100000), 5000)\n",
    "\n",
    "print(\"The pure Python method takes %s seconds\" % PyPairs(inAPy, inBPy)[0])\n",
    "print(\"The NumPy method takes %s seconds\" % NpPairs(inANp, inBNp)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## Question 2: **Fascinating Flowers**\n",
    "\n",
    "As we are just starting on a data science path, we will start with one of the most famous datasets for beginners, the _Iris Flower Dataset_. Published by [Ronald Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher) in 1936, the dataset has become a common test case for statistical machine learning methods. However today, we will be using it for learning NumPy.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Picture this**: You've been successful in applying for an internship at the ANU, under the [Fenner School of Environment and Society](https://fennerschool.anu.edu.au). Known for their interest in the world we live in and famous for their [_What The Fluff?_](https://fennerschool.anu.edu.au/news-events/news/what-fluff) and [_A Buzz About Pollination_](https://fennerschool.anu.edu.au/research/research-stories/buzz-about-pollination-fenner-research-maps-bee-and-food-crops-place) style research pieces, researchers in the school want to know how they can incorporate data analytics more into their research. Being the genius you are, you decide that you will write code to demonstrate the strengths of data analysis, on a dataset they will take interest in: the Iris Flower Dataset.\n",
    "\n",
    "Your task is to showcase how NumPy can be used for manipulating data and providing _meaningful_ insight into the data a user is interacting with, using the Iris Flower Dataset as your example dataset.\n",
    "\n",
    "The dataset features the following information:\n",
    "\n",
    "| Column Name    | Description                      |\n",
    "| :------------: | :------------:                   |\n",
    "| sepal_length   | Length of the Sepal (end to end) |\n",
    "| sepal_width    | Width of the Sepal (end to end)  |\n",
    "| petal_length   | Length of the Petal (end to end) |\n",
    "| petal_width    | Width of the Petal (end to end)  |\n",
    "| Species        | Type of Iris Flower              |\n",
    "\n",
    "For those who are unsure what the table columns refer to, the sepal and petal is outlined on the diagram below\n",
    "\n",
    "<img src=\"./img/diagramSepal.jpg\" alt=\"Flower Diagram\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "****\n",
    "\n",
    "### Q2.1: Importing Data & Making It Useable\n",
    "\n",
    "There a number of standard actions that will need to be performed to get the data to a \"useable\" point, then we can start experimenting with the data. The following actions will get the data to a \"useable point\":\n",
    "- Importing the data into a 2D NumPy array from the csv (csv location: `./data/IRIS.csv`)\n",
    "- Reducing the data to only make use of the `sepal_length`, `sepal_width`, `petal_length` & `petal_width` columns. We will use the species column in later labs.\n",
    "\n",
    "The NumPy function `genfromtxt` will assist you greatly in being able to perform the above actions. [Documentation is here](https://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code Here\n",
    "file = np.genfromtxt(\"./data/IRIS.csv\", delimiter =',', skip_header =1, usecols=(0,1,2,3))\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array[row_start:row_end, col_start:col_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[0:9,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Q2.2: Finding Meaning\n",
    "Now that we have some data that can be used, we can start finding statistical information in the NumPy data structure. Using NumPy functions, we want to find the statistical information that exists for the length and widths of the sepal and petal for the observed flowers.\n",
    "\n",
    "With the knowledge of the first 50 entries in the dataset being the flower type `Iris-setosa`, entries 51-100 being `Iris-versicolor` and the last 50 entries being `Iris-virginica`, we want to determine the relative sizes of the entire Iris family, and the unique aspects of each Iris flower. This includes the following actions:\n",
    "- Determining the mean, minimum and maximum Sepal and Petal dimensions for the entire Iris family\n",
    "- Determining the mean, minimum and maximum Sepal and Petal dimensions for each Iris sub-species (Setosa, Versicolor and Virginica)\n",
    "- Determining the standard deviation & variance of the Petal and Sepal dimensions for both the Iris family as a whole, and each sub-species.\n",
    "\n",
    "With this information, we should be able to answer questions using the evidence found by interacting with the dataset. Find the metrics specified above and any others that you deem useful, and answer the text questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire min, max, mean is:  [4.3, 2.0, 1.0, 0.1] [7.9, 4.4, 6.9, 2.5] [5.843333333333334, 3.0540000000000003, 3.758666666666666, 1.1986666666666668]\n",
      "Setosa Sepal legnth minimum is:  4.3\n",
      "Setosa Sepal legnth maximum is:  5.8\n",
      "Setosa Sepal legnth meam is:  5.006\n",
      "Setosa Sepal width minimum is:  2.3\n",
      "Setosa Sepal width maximum is:  4.4\n",
      "Setosa Sepal width meam is:  3.418\n"
     ]
    }
   ],
   "source": [
    "# Your Code Here\n",
    "entire_min = [np.min(file[:,0]), np.min(file[:,1]), np.min(file[:,2]),np.min(file[:,3])]\n",
    "entire_max = [np.max(file[:,0]), np.max(file[:,1]), np.max(file[:,2]),np.max(file[:,3])]\n",
    "entire_mean = [np.mean(file[:,0]), np.mean(file[:,1]), np.mean(file[:,2]),np.mean(file[:,3])]\n",
    "print(\"Entire min, max, mean is: \", entire_min, entire_max, entire_mean)\n",
    "\n",
    "setosa_splen = file[:50,0]\n",
    "setosa_spwid = file[:50,1]\n",
    "setosa_ptlen = file[:50,2]\n",
    "setosa_ptwid = file[:50,3]\n",
    "print(\"Setosa Sepal legnth minimum is: \",setosa_splen.min())\n",
    "print(\"Setosa Sepal legnth maximum is: \",setosa_splen.max())\n",
    "print(\"Setosa Sepal legnth meam is: \",setosa_splen.mean())\n",
    "print(\"Setosa Sepal width minimum is: \",setosa_spwid.min())\n",
    "print(\"Setosa Sepal width maximum is: \",setosa_spwid.max())\n",
    "print(\"Setosa Sepal width meam is: \",setosa_spwid.mean())\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What is the average petal width and length of a flower in the Iris family?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Your Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What is the smallest flower (by petal dimensions) observed in the Iris-Setosa sub-species? Does this smaller size correlate to the Sepal dimensions?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Your Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What is the largest sub-species of the Iris family? How did you determine this?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "While these questions have been directly related to the data and are easily answered, some require a bit less procedural thought and a bit of problem solving. The following is designed to be a precursor to the machine learning work later in the semester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Based on the size dimensions you found above, is there a way that you can categorise a type of flower based on it's petal and sepal dimensions? \n",
    "##### Provide a short description of how you would perform this, and provide a proof of concept in the form of code with some example cases."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Your text description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your Proof of Concept here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Finally, remember the original context of this overall question. You were finding meaning in the data to show the Fenner School of Environment and Society how data science can be useful in their research. It would be reasonable to assume that a number of the people you would show this to would have varying levels of coding experience, some with no experience whatsoever. Before moving on, make sure your code is readable and commented so that you any person could understand what your code is doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## Question 3: Caring about Cars\n",
    "\n",
    "Imagine you are trying to help your friends find their ideal dream car, based on the car's performance and fuel economy. In this scenario, we are going to walk through some steps to find an ideal choice of cars given some restrictions given to us, in a step by step case. In the future, you will have to come up with these steps yourself or intepret them from an initial briefing, so this is good practice!\n",
    "\n",
    "The dataset we are using is a dataset of American cars. The dataset has the following schema:\n",
    "\n",
    "| Column Name    | Description    |\n",
    "| :------------- | :------------- |\n",
    "| type           | The car's manufacturer and make/model       |\n",
    "| mpg            | The cars fuel consumption, in _miles per gallon_ (mpg) |\n",
    "| cyl            | The number of cylinders in the car's engine | \n",
    "| disp           | The combined swept volume of the pistons inside the cylinders of the car's engine |\n",
    "| hp             | The car's horsepower |\n",
    "| wt             | The weight of the car, in pounds |\n",
    "| speed          | A relative measure of the top speed of the car, bespoke format |\n",
    "\n",
    "We will need to do some alterations of the data to shift some metrics (mainly \"mpg\", \"hp\" and \"wt\") from Americanised metrics to more internationally accepted measurements, then we will be able to perform some analysis to find the ideal car based on some limitations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, lets import the dataset. Using the [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) function will be ideal for this. Print out the first 5 rows to ensure the data is held correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "import pandas as pd\n",
    "cars_data = pd.read_csv('./data/cars.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.1: Maladapted Metrics\n",
    "Unfortunately, a lot of datasets have been formed in America (and the UK) and follow their conventions for data metrics such as miles, pounds, and horsepower. Before we work on this dataset, we aim to change that. Your task is as follows:\n",
    "- Convert the mpg column's entries into litres/100km. Create a new column for these called l/100km and provide the converted value for each car in that row.\n",
    "- Convert the hp column's entries into Kilowatts. Create a new column for these called kw and provide the converted value for each car in that row.\n",
    "- Convert the wt column's entries into Kilograms. Create a new column for these called kg and provide the converted value for each car in that row.\n",
    "\n",
    "Formulas:\n",
    "- 235.215/(x mpg) = y L/100 km\n",
    "- x hp / 1.341 = y kw\n",
    "- 1 lbs / 2.205 = y kg\n",
    "\n",
    "Further information on the formulas can be found online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>wt</th>\n",
       "      <th>speed</th>\n",
       "      <th>l/100km</th>\n",
       "      <th>kw</th>\n",
       "      <th>kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMC Ambassador Brougham</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>3821</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.093462</td>\n",
       "      <td>130.499627</td>\n",
       "      <td>1732.879819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMC Ambassador DPL</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>390.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3850</td>\n",
       "      <td>8.5</td>\n",
       "      <td>15.681000</td>\n",
       "      <td>141.685309</td>\n",
       "      <td>1746.031746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMC Ambassador SST</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3672</td>\n",
       "      <td>11.5</td>\n",
       "      <td>13.836176</td>\n",
       "      <td>111.856823</td>\n",
       "      <td>1665.306122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMC Concord DL 6</td>\n",
       "      <td>20.2</td>\n",
       "      <td>6</td>\n",
       "      <td>232.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3265</td>\n",
       "      <td>18.2</td>\n",
       "      <td>11.644307</td>\n",
       "      <td>67.114094</td>\n",
       "      <td>1480.725624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMC Concord DL</td>\n",
       "      <td>18.1</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3410</td>\n",
       "      <td>15.1</td>\n",
       "      <td>12.995304</td>\n",
       "      <td>89.485459</td>\n",
       "      <td>1546.485261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Volvo 145E (Wagon)</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2933</td>\n",
       "      <td>14.5</td>\n",
       "      <td>13.067500</td>\n",
       "      <td>83.519761</td>\n",
       "      <td>1330.158730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>Volvo 244DL</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2945</td>\n",
       "      <td>14.5</td>\n",
       "      <td>10.691591</td>\n",
       "      <td>73.079791</td>\n",
       "      <td>1335.600907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>Volvo 245</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>3150</td>\n",
       "      <td>15.7</td>\n",
       "      <td>11.760750</td>\n",
       "      <td>76.062640</td>\n",
       "      <td>1428.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>Volvo 264GL</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6</td>\n",
       "      <td>163.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>3140</td>\n",
       "      <td>13.6</td>\n",
       "      <td>13.836176</td>\n",
       "      <td>93.214019</td>\n",
       "      <td>1424.036281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Volvo Diesel</td>\n",
       "      <td>30.7</td>\n",
       "      <td>6</td>\n",
       "      <td>145.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>3160</td>\n",
       "      <td>19.6</td>\n",
       "      <td>7.661726</td>\n",
       "      <td>56.674124</td>\n",
       "      <td>1433.106576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        type   mpg  cyl   disp     hp    wt  speed    l/100km  \\\n",
       "0    AMC Ambassador Brougham  13.0    8  360.0  175.0  3821   11.0  18.093462   \n",
       "1         AMC Ambassador DPL  15.0    8  390.0  190.0  3850    8.5  15.681000   \n",
       "2         AMC Ambassador SST  17.0    8  304.0  150.0  3672   11.5  13.836176   \n",
       "3           AMC Concord DL 6  20.2    6  232.0   90.0  3265   18.2  11.644307   \n",
       "4             AMC Concord DL  18.1    6  258.0  120.0  3410   15.1  12.995304   \n",
       "..                       ...   ...  ...    ...    ...   ...    ...        ...   \n",
       "401       Volvo 145E (Wagon)  18.0    4  121.0  112.0  2933   14.5  13.067500   \n",
       "402              Volvo 244DL  22.0    4  121.0   98.0  2945   14.5  10.691591   \n",
       "403                Volvo 245  20.0    4  130.0  102.0  3150   15.7  11.760750   \n",
       "404              Volvo 264GL  17.0    6  163.0  125.0  3140   13.6  13.836176   \n",
       "405             Volvo Diesel  30.7    6  145.0   76.0  3160   19.6   7.661726   \n",
       "\n",
       "             kw           kg  \n",
       "0    130.499627  1732.879819  \n",
       "1    141.685309  1746.031746  \n",
       "2    111.856823  1665.306122  \n",
       "3     67.114094  1480.725624  \n",
       "4     89.485459  1546.485261  \n",
       "..          ...          ...  \n",
       "401   83.519761  1330.158730  \n",
       "402   73.079791  1335.600907  \n",
       "403   76.062640  1428.571429  \n",
       "404   93.214019  1424.036281  \n",
       "405   56.674124  1433.106576  \n",
       "\n",
       "[406 rows x 10 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code here\n",
    "cars_data['l/100km'] = 235.215 / cars_data['mpg']\n",
    "cars_data['kw'] = cars_data['hp'] / 1.341\n",
    "cars_data['kg'] = cars_data['wt'] / 2.205\n",
    "cars_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.2: Chaotic Cars\n",
    "Now that we have the data in a more internationally accepted fashion, you are tasked in finding the best car for your friend Ben. Ben doesn't know much about cars but cares for the environment, so there will be considerations for the fuel economy of the car. Your task is as follows:\n",
    "- Find the top 15 cars with the lowest l/100km rating. These cars used the least amount of fuel when travelling.\n",
    "- While Ben wants to be fuel efficient, he also wants to be able to race his friend Afzal. From the top 15 cars, find the top 10 that have the highest Power-to-Weight ratio. This is calculated by: `kw / kg`\n",
    "- With the choice narrowed down to 10, make an argument for which 3 cars would be best for Ben and why. Consider that he wants to race Afzal so speed is important, and the number of cylinders might also impact how the car may behave (more cylinders generally means larger displacement because more petrol can get into the engine at any one time).\n",
    "\n",
    "Provide your code below for the first two tasks, and provide text and code responses (evidenced by the data) for which cars are best for Ben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>wt</th>\n",
       "      <th>speed</th>\n",
       "      <th>l/100km</th>\n",
       "      <th>kw</th>\n",
       "      <th>kg</th>\n",
       "      <th>power_to_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Toyota Corolla Tercel</td>\n",
       "      <td>38.1</td>\n",
       "      <td>4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1968</td>\n",
       "      <td>18.8</td>\n",
       "      <td>6.173622</td>\n",
       "      <td>44.742729</td>\n",
       "      <td>892.517007</td>\n",
       "      <td>0.050131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Mazda GLC</td>\n",
       "      <td>46.6</td>\n",
       "      <td>4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2110</td>\n",
       "      <td>17.9</td>\n",
       "      <td>5.047532</td>\n",
       "      <td>48.471290</td>\n",
       "      <td>956.916100</td>\n",
       "      <td>0.050654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Datsun 210</td>\n",
       "      <td>40.8</td>\n",
       "      <td>4</td>\n",
       "      <td>85.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2110</td>\n",
       "      <td>19.2</td>\n",
       "      <td>5.765074</td>\n",
       "      <td>48.471290</td>\n",
       "      <td>956.916100</td>\n",
       "      <td>0.050654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Toyota Starlet</td>\n",
       "      <td>39.1</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1755</td>\n",
       "      <td>16.9</td>\n",
       "      <td>6.015729</td>\n",
       "      <td>43.251305</td>\n",
       "      <td>795.918367</td>\n",
       "      <td>0.054341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Datsun B210 GX</td>\n",
       "      <td>39.4</td>\n",
       "      <td>4</td>\n",
       "      <td>85.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2070</td>\n",
       "      <td>18.6</td>\n",
       "      <td>5.969924</td>\n",
       "      <td>52.199851</td>\n",
       "      <td>938.775510</td>\n",
       "      <td>0.055604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Honda Civic</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.189868</td>\n",
       "      <td>49.962714</td>\n",
       "      <td>891.156463</td>\n",
       "      <td>0.056065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Plymouth Champ</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1875</td>\n",
       "      <td>16.4</td>\n",
       "      <td>6.031154</td>\n",
       "      <td>47.725578</td>\n",
       "      <td>850.340136</td>\n",
       "      <td>0.056125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Volkswagen Rabbit</td>\n",
       "      <td>41.5</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2144</td>\n",
       "      <td>14.7</td>\n",
       "      <td>5.667831</td>\n",
       "      <td>56.674124</td>\n",
       "      <td>972.335601</td>\n",
       "      <td>0.058287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Honda Civic 1500 GL</td>\n",
       "      <td>44.6</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1850</td>\n",
       "      <td>13.8</td>\n",
       "      <td>5.273879</td>\n",
       "      <td>49.962714</td>\n",
       "      <td>839.002268</td>\n",
       "      <td>0.059550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Renault Lecar Deluxe</td>\n",
       "      <td>40.9</td>\n",
       "      <td>4</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1835</td>\n",
       "      <td>17.3</td>\n",
       "      <td>5.750978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>832.199546</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      type   mpg  cyl  disp    hp    wt  speed   l/100km  \\\n",
       "357  Toyota Corolla Tercel  38.1    4  89.0  60.0  1968   18.8  6.173622   \n",
       "247              Mazda GLC  46.6    4  86.0  65.0  2110   17.9  5.047532   \n",
       "117             Datsun 210  40.8    4  85.0  65.0  2110   19.2  5.765074   \n",
       "373         Toyota Starlet  39.1    4  79.0  58.0  1755   16.9  6.015729   \n",
       "130         Datsun B210 GX  39.4    4  85.0  70.0  2070   18.6  5.969924   \n",
       "237            Honda Civic  38.0    4  91.0  67.0  1965   15.0  6.189868   \n",
       "290         Plymouth Champ  39.0    4  86.0  64.0  1875   16.4  6.031154   \n",
       "395      Volkswagen Rabbit  41.5    4  98.0  76.0  2144   14.7  5.667831   \n",
       "232    Honda Civic 1500 GL  44.6    4  91.0  67.0  1850   13.8  5.273879   \n",
       "340   Renault Lecar Deluxe  40.9    4  85.0   NaN  1835   17.3  5.750978   \n",
       "\n",
       "            kw          kg  power_to_weight  \n",
       "357  44.742729  892.517007         0.050131  \n",
       "247  48.471290  956.916100         0.050654  \n",
       "117  48.471290  956.916100         0.050654  \n",
       "373  43.251305  795.918367         0.054341  \n",
       "130  52.199851  938.775510         0.055604  \n",
       "237  49.962714  891.156463         0.056065  \n",
       "290  47.725578  850.340136         0.056125  \n",
       "395  56.674124  972.335601         0.058287  \n",
       "232  49.962714  839.002268         0.059550  \n",
       "340        NaN  832.199546              NaN  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code Here\n",
    "top_15 = cars_data.sort_values(by=['l/100km']).head(15)\n",
    "cars_data['Power_to_Weight'] = cars_data['kw'] / cars_data['kg']\n",
    "top_10 = top_15.sort_values(by=['Power_to_Weight']).tail(10)\n",
    "top_10.drop(columns=['Power_to_Weight','Power_to_weight'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Your Text Response here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Code Cell as necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what do you think of your choice? Check with those around you in the lab (or your friends if you are doing this at home) to see what cars others have chosen, and why. In groups, come up with the best car and state your case to your tutor. After that, you're done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework & Extension Questions\n",
    "No formal homework is set for this week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "## Resources\n",
    "- [Numpy Manual v1.17](https://docs.scipy.org/doc/numpy/)\n",
    "- [Pandas Docs v0.25.3](https://pandas.pydata.org/pandas-docs/stable/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
